# =============================================================================
# Airflow Common Configuration
# =============================================================================
x-airflow-common:
  &airflow-common
  build: .
  env_file:
    - ${ENV_FILE_PATH:-.env}
  environment:
    &airflow-common-env
    # Core Airflow settings
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY:-}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__EXECUTION_API_SERVER_URL: 'http://airflow-apiserver:8080/execution/'
    AIRFLOW_CONFIG: ${AIRFLOW_CONFIG:-/opt/airflow/config/airflow.cfg}
    AIRFLOW__LOGGING__LOGGING_CONFIG_CLASS: logging_config.LOGGING_CONFIG
    # Database connections
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_POSTGRES_USER:-airflow}:${AIRFLOW_POSTGRES_PASSWORD:-airflow}@airflow-db/${AIRFLOW_POSTGRES_DB:-airflow}
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${AIRFLOW_POSTGRES_USER:-airflow}:${AIRFLOW_POSTGRES_PASSWORD:-airflow}@airflow-db/${AIRFLOW_POSTGRES_DB:-airflow}
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    # Scheduler settings
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    # OpenLineage integration
    OPENLINEAGE_NAMESPACE: ${OPENLINEAGE_NAMESPACE:-strava-datastack}
    AIRFLOW__OPENLINEAGE__NAMESPACE: ${OPENLINEAGE_NAMESPACE:-strava-datastack}
    AIRFLOW__OPENLINEAGE__TRANSPORT: '${AIRFLOW__OPENLINEAGE__TRANSPORT:-{"type":"http","url":"http://marquez:5000","endpoint":"api/v1/lineage"}}'
    # OpenTelemetry Metrics
    AIRFLOW__METRICS__OTEL_ON: 'true'
    AIRFLOW__METRICS__OTEL_HOST: otel-collector
    AIRFLOW__METRICS__OTEL_PORT: '4318'
    AIRFLOW__METRICS__OTEL_PREFIX: airflow
    AIRFLOW__METRICS__OTEL_INTERVAL_MILLISECONDS: '60000'
    AIRFLOW__METRICS__OTEL_SERVICE: airflow
    # OpenTelemetry Traces
    AIRFLOW__TRACES__OTEL_ON: 'true'
    AIRFLOW__TRACES__OTEL_HOST: otel-collector
    AIRFLOW__TRACES__OTEL_PORT: '4318'
    AIRFLOW__TRACES__OTEL_SERVICE: airflow
    # Application settings
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    DUCKDB_PATH: ${DUCKDB_PATH:-/opt/airflow/data/strava_datastack.duckdb}
    DUCKDB_REPORTING_PATH: ${DUCKDB_REPORTING_PATH:-/opt/airflow/data/strava_reporting.duckdb}
    STRAVA_ENVIRONMENT: ${STRAVA_ENVIRONMENT:-production}
  volumes:
    - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
    - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
    - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
    - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
    - ${AIRFLOW_PROJ_DIR:-.}/scripts:/opt/airflow/scripts
    - ../extract:/opt/airflow/extract
    - ../transform:/opt/airflow/transform
    - ${AIRFLOW_PROJ_DIR:-.}/data:/opt/airflow/data
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    &airflow-common-depends-on
    redis:
      condition: service_healthy
    airflow-db:
      condition: service_healthy

services:
  # ===========================================================================
  # Infrastructure Services
  # ===========================================================================
  airflow-db:
    image: postgres:16
    environment:
      POSTGRES_USER: ${AIRFLOW_POSTGRES_USER:-airflow}
      POSTGRES_PASSWORD: ${AIRFLOW_POSTGRES_PASSWORD:-airflow}
      POSTGRES_DB: ${AIRFLOW_POSTGRES_DB:-airflow}
    volumes:
      - airflow-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${AIRFLOW_POSTGRES_USER:-airflow}"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  redis:
    # Redis is limited to 7.2-bookworm due to licencing change
    # https://redis.io/blog/redis-adopts-dual-source-available-licensing/
    image: redis:7.2-bookworm
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always

  # ===========================================================================
  # OpenLineage / Marquez Services (profile: lineage)
  # ===========================================================================
  marquez-db:
    profiles:
      - lineage
      - all
    image: postgres:16
    environment:
      POSTGRES_USER: ${MARQUEZ_POSTGRES_USER:-marquez}
      POSTGRES_PASSWORD: ${MARQUEZ_POSTGRES_PASSWORD:-marquez}
      POSTGRES_DB: ${MARQUEZ_POSTGRES_DB:-marquez}
    volumes:
      - marquez-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${MARQUEZ_POSTGRES_USER:-marquez}"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  marquez:
    profiles:
      - lineage
      - all
    image: marquezproject/marquez:0.51.1
    environment:
      POSTGRES_HOST: marquez-db
      POSTGRES_PORT: 5432
      POSTGRES_DB: ${MARQUEZ_POSTGRES_DB:-marquez}
      POSTGRES_USER: ${MARQUEZ_POSTGRES_USER:-marquez}
      POSTGRES_PASSWORD: ${MARQUEZ_POSTGRES_PASSWORD:-marquez}
      MARQUEZ_PORT: 5000
      MARQUEZ_ADMIN_PORT: 5001
    ports:
      - "5000:5000"
      - "5001:5001"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5001/healthcheck"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      marquez-db:
        condition: service_healthy
    restart: always

  marquez-web:
    profiles:
      - lineage
      - all
    image: marquezproject/marquez-web:0.51.1
    environment:
      MARQUEZ_HOST: marquez
      MARQUEZ_PORT: 5000
      WEB_PORT: 3000
    ports:
      - "3001:3000"
    depends_on:
      marquez:
        condition: service_healthy
    restart: always

  # ===========================================================================
  # OpenTelemetry Observability Stack (profile: otel)
  # ===========================================================================
  elasticsearch:
    profiles:
      - otel
      - all
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - cluster.name=jaeger-cluster
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=5s"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    restart: always

  otel-collector:
    profiles:
      - otel
      - all
    image: otel/opentelemetry-collector-contrib:0.96.0
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/config/otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "8889:8888"   # Prometheus metrics exporter
      - "13133:13133" # Health check
      - "55679:55679" # zPages
    environment:
      STRAVA_ENVIRONMENT: ${STRAVA_ENVIRONMENT:-production}
    healthcheck:
      test: ["CMD", "/otelcol-contrib", "--version"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      jaeger:
        condition: service_healthy
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
    restart: always

  jaeger:
    profiles:
      - otel
      - all
    image: jaegertracing/all-in-one:1.54
    environment:
      COLLECTOR_OTLP_ENABLED: 'true'
      SPAN_STORAGE_TYPE: elasticsearch
      ES_SERVER_URLS: http://elasticsearch:9200
      ES_TAGS_AS_FIELDS_ALL: 'true'
    ports:
      - "16686:16686"  # Jaeger UI
      - "14269:14269"  # Admin/health port
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:14269/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: always

  prometheus:
    profiles:
      - otel
      - all
    image: prom/prometheus:v2.50.0
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-remote-write-receiver'
      - '--web.enable-lifecycle'
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: always

  loki:
    profiles:
      - otel
      - all
    image: grafana/loki:2.9.4
    command: -config.file=/etc/loki/config.yaml
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/config/loki-config.yaml:/etc/loki/config.yaml:ro
      - loki-data:/loki
    ports:
      - "3100:3100"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3100/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: always

  promtail:
    profiles:
      - otel
      - all
    image: grafana/promtail:2.9.4
    command: -config.file=/etc/promtail/config.yaml
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/config/promtail-config.yaml:/etc/promtail/config.yaml:ro
      - ${AIRFLOW_PROJ_DIR:-.}/logs:/var/log/airflow:ro
    depends_on:
      loki:
        condition: service_healthy
    restart: always

  grafana:
    profiles:
      - otel
      - all
    image: grafana/grafana:10.3.3
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: 'false'
      GF_FEATURE_TOGGLES_ENABLE: traceqlEditor
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/config/grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana-data:/var/lib/grafana
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
      jaeger:
        condition: service_healthy
    restart: always

  # ===========================================================================
  # Airflow Core Services (profile: airflow)
  # ===========================================================================
  airflow-init:
    <<: *airflow-common
    profiles:
      - airflow
      - all
    entrypoint: /bin/bash
    # yamllint disable rule:line-length
    command:
      - -c
      - /opt/airflow/scripts/airflow-init.sh
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: ${_AIRFLOW_DB_MIGRATE:-true}
      _AIRFLOW_WWW_USER_CREATE: ${_AIRFLOW_WWW_USER_CREATE:-true}
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    user: "0:0"

  airflow-apiserver:
    <<: *airflow-common
    profiles:
      - airflow
      - all
    command: api-server
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/api/v2/version"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    profiles:
      - airflow
      - all
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-dag-processor:
    <<: *airflow-common
    profiles:
      - airflow
      - all
    command: dag-processor
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type DagProcessorJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-worker:
    <<: *airflow-common
    profiles:
      - airflow
      - all
    command: celery worker
    healthcheck:
      # yamllint disable rule:line-length
      test: ["CMD-SHELL", "celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d 'celery@$${HOSTNAME}' || celery --app airflow.executors.celery_executor.app inspect ping -d 'celery@$${HOSTNAME}'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    environment:
      <<: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: ${DUMB_INIT_SETSID:-0}
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-apiserver:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully

  airflow-triggerer:
    <<: *airflow-common
    profiles:
      - airflow
      - all
    command: triggerer
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  # ===========================================================================
  # Airflow Utility Services
  # ===========================================================================
  airflow-cli:
    <<: *airflow-common
    profiles:
      - debug
    environment:
      <<: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: ${CONNECTION_CHECK_MAX_COUNT:-0}
    command:
      - bash
      - -c
      - airflow
    depends_on:
      <<: *airflow-common-depends-on

  flower:
    <<: *airflow-common
    profiles:
      - flower
      - all
    command: celery flower
    ports:
      - "5555:5555"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

# =============================================================================
# Volumes
# =============================================================================
volumes:
  airflow-db-volume:
  marquez-db-volume:
  elasticsearch-data:
  prometheus-data:
  grafana-data:
  loki-data:
